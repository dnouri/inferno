{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`skorch`* is designed to maximize interoperability between `sklearn` and `pytorch`. The aim is to keep 99% of the flexibility of `pytorch` while being able to leverage most features of `sklearn`. Below, we show the basic usage of `skorch` and how it can be combined with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Definition of the pytorch module](#Definition-of-the-pytorch-module)\n",
    "* [Training a model and predicting](#Training-a-model-and-predicting)\n",
    "* [Saving and loading a model](#Saving-and-loading-a-model)\n",
    "* [Usage with an sklearn Pipeline](#Usage-with-an-sklearn-Pipeline)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Grid search](#Usage-with-sklearn-GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a toy binary classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,), 0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the `pytorch module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a vanilla neural network with two hidden layers. The output layer should have 2 output units since there are two classes. In addition, it should have a softmax nonlinearity, because later, when calling `predict_proba`, the output from the `forward` call will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model and predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `NeuralNetClassifier` because we're dealing with a classifcation task. The first argument should be the `pytorch module`. As additional arguments, we pass the number of epochs and the learning rate (`lr`), but those are optional.\n",
    "\n",
    "*Note*: To use the cuda backend, pass `use_cuda=True` as an additional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skorch.net import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`. By default, `NeuralNetClassifier` makes a `StratifiedKFold` split on the data (80/20) to track the validation loss. This is shown, as well as the train loss and the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7111\u001b[0m       \u001b[32m0.5100\u001b[0m        \u001b[35m0.6894\u001b[0m  0.1245\n",
      "      2        \u001b[36m0.6928\u001b[0m       \u001b[32m0.5500\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0601\n",
      "      3        \u001b[36m0.6833\u001b[0m       \u001b[32m0.5650\u001b[0m        \u001b[35m0.6741\u001b[0m  0.0546\n",
      "      4        \u001b[36m0.6763\u001b[0m       \u001b[32m0.5850\u001b[0m        \u001b[35m0.6674\u001b[0m  0.0865\n",
      "      5        \u001b[36m0.6727\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6616\u001b[0m  0.0726\n",
      "      6        \u001b[36m0.6606\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.6536\u001b[0m  0.0697\n",
      "      7        \u001b[36m0.6560\u001b[0m       0.6600        \u001b[35m0.6443\u001b[0m  0.0777\n",
      "      8        \u001b[36m0.6427\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6354\u001b[0m  0.0789\n",
      "      9        \u001b[36m0.6300\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.6264\u001b[0m  0.0956\n",
      "     10        \u001b[36m0.6289\u001b[0m       0.6800        \u001b[35m0.6189\u001b[0m  0.0537\n",
      "     11        \u001b[36m0.6241\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6114\u001b[0m  0.0778\n",
      "     12        \u001b[36m0.6132\u001b[0m       0.7150        \u001b[35m0.6017\u001b[0m  0.0533\n",
      "     13        \u001b[36m0.5950\u001b[0m       \u001b[32m0.7350\u001b[0m        \u001b[35m0.5902\u001b[0m  0.0703\n",
      "     14        \u001b[36m0.5914\u001b[0m       0.7200        \u001b[35m0.5831\u001b[0m  0.0805\n",
      "     15        \u001b[36m0.5784\u001b[0m       0.7300        \u001b[35m0.5733\u001b[0m  0.0624\n",
      "     16        0.5816       \u001b[32m0.7400\u001b[0m        \u001b[35m0.5665\u001b[0m  0.0674\n",
      "     17        \u001b[36m0.5766\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m0.5616\u001b[0m  0.0596\n",
      "     18        \u001b[36m0.5636\u001b[0m       0.7450        \u001b[35m0.5559\u001b[0m  0.0610\n",
      "     19        \u001b[36m0.5517\u001b[0m       0.7350        \u001b[35m0.5527\u001b[0m  0.0633\n",
      "     20        0.5570       0.7350        \u001b[35m0.5492\u001b[0m  0.0586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<skorch.net.NeuralNetClassifier at 0x7fb8d31230f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(X[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33409804,  0.66590196],\n",
       "       [ 0.65906334,  0.34093666],\n",
       "       [ 0.70409262,  0.29590738],\n",
       "       [ 0.70345545,  0.29654452],\n",
       "       [ 0.65079051,  0.34920952]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = net.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save and load either the whole model by using pickle or just the learned model parameters by calling `save_params` and `load_params`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '/tmp/mymodel.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    new_net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only saves and loads the proper `module` parameters, meaning that hyperparameters such as `lr` and `max_epochs` are not saved. Therefore, to load the model, we have to re-initialize it beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.save_params(file_name)  # a file handler also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first initialize the model\n",
    "new_net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    ").initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_net.load_params(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage with an `sklearn Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to put the `NeuralNetClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', net),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module!\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7102\u001b[0m       \u001b[32m0.5050\u001b[0m        \u001b[35m0.6991\u001b[0m  0.0688\n",
      "      2        \u001b[36m0.6971\u001b[0m       \u001b[32m0.5100\u001b[0m        \u001b[35m0.6940\u001b[0m  0.0633\n",
      "      3        \u001b[36m0.6885\u001b[0m       \u001b[32m0.5350\u001b[0m        \u001b[35m0.6896\u001b[0m  0.0443\n",
      "      4        \u001b[36m0.6878\u001b[0m       \u001b[32m0.5450\u001b[0m        \u001b[35m0.6863\u001b[0m  0.0516\n",
      "      5        \u001b[36m0.6821\u001b[0m       \u001b[32m0.5750\u001b[0m        \u001b[35m0.6833\u001b[0m  0.0962\n",
      "      6        0.6845       \u001b[32m0.5850\u001b[0m        \u001b[35m0.6802\u001b[0m  0.0668\n",
      "      7        \u001b[36m0.6751\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6760\u001b[0m  0.0601\n",
      "      8        \u001b[36m0.6716\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0644\n",
      "      9        \u001b[36m0.6676\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6669\u001b[0m  0.0650\n",
      "     10        \u001b[36m0.6575\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.6591\u001b[0m  0.0552\n",
      "     11        \u001b[36m0.6510\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6514\u001b[0m  0.0677\n",
      "     12        \u001b[36m0.6497\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6439\u001b[0m  0.1023\n",
      "     13        \u001b[36m0.6370\u001b[0m       0.7100        \u001b[35m0.6335\u001b[0m  0.0574\n",
      "     14        \u001b[36m0.6274\u001b[0m       0.7100        \u001b[35m0.6241\u001b[0m  0.0513\n",
      "     15        0.6306       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6149\u001b[0m  0.0691\n",
      "     16        \u001b[36m0.6086\u001b[0m       0.7200        \u001b[35m0.6052\u001b[0m  0.0855\n",
      "     17        \u001b[36m0.5949\u001b[0m       0.7150        \u001b[35m0.5958\u001b[0m  0.0777\n",
      "     18        0.6004       0.7150        \u001b[35m0.5880\u001b[0m  0.0645\n",
      "     19        \u001b[36m0.5946\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5810\u001b[0m  0.0878\n",
      "     20        \u001b[36m0.5933\u001b[0m       0.7250        \u001b[35m0.5763\u001b[0m  0.0716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('net', <skorch.net.NeuralNetClassifier object at 0x7fb8d31230f0>)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38140485,  0.61859512],\n",
       "       [ 0.67595905,  0.32404095],\n",
       "       [ 0.58000326,  0.41999674],\n",
       "       [ 0.65313405,  0.34686592],\n",
       "       [ 0.65428513,  0.34571484]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = pipe.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the whole pipeline, including the pytorch module, use `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new callback to the model is straightforward. Below we show how to add a new score to the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add area under the ROC (AUC) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skorch.callbacks import Scoring\n",
    "from skorch.utils import to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a scoring callback in skorch, `Scoring`, which we use for this. We need to specify a `name` of the score, as well as which score to calculate. Here we just pass a string, `'roc_auc_score'`, as score. For a list of all existing scores, look [here](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics). We could also pass a function with the signature `func(model, X, y) -> score`, or `None`, in which case the `score` method of the model is used. Note that this is exactly the same behavior as in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc = Scoring(\n",
    "    name='AUC',\n",
    "    scoring='roc_auc_score',\n",
    "    lower_is_better=False,\n",
    "    pred_extractor=lambda y_proba: to_numpy(y_proba)[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we should tell the callback that higher scores are better (to get the correct colors printed below), and how to extract the data from the prediction. The latter must be specified because sometimes we need the class predictions, sometimes the class probabilities, and sometimes, as in this example, only probability of the `1` class. Moreover, we must convert the data from `torch` tensors to `numpy` arrays (using the helper function `to_numpy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    callbacks=[auc],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we pass the scoring callback to the `callbacks` parameter as a list and then call `fit`. Notice that we get the printed scores and color highlighting for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch     AUC    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.6722\u001b[0m        \u001b[32m0.6730\u001b[0m       \u001b[35m0.6100\u001b[0m        \u001b[31m0.6730\u001b[0m  0.0969\n",
      "      2  \u001b[36m0.6990\u001b[0m        \u001b[32m0.6469\u001b[0m       \u001b[35m0.6650\u001b[0m        \u001b[31m0.6621\u001b[0m  0.0831\n",
      "      3  \u001b[36m0.7084\u001b[0m        \u001b[32m0.6423\u001b[0m       0.6500        \u001b[31m0.6548\u001b[0m  0.0896\n",
      "      4  \u001b[36m0.7171\u001b[0m        \u001b[32m0.6257\u001b[0m       \u001b[35m0.6700\u001b[0m        \u001b[31m0.6482\u001b[0m  0.0780\n",
      "      5  \u001b[36m0.7255\u001b[0m        0.6308       \u001b[35m0.6750\u001b[0m        \u001b[31m0.6402\u001b[0m  0.0748\n",
      "      6  \u001b[36m0.7358\u001b[0m        \u001b[32m0.6043\u001b[0m       0.6650        \u001b[31m0.6330\u001b[0m  0.0882\n",
      "      7  \u001b[36m0.7402\u001b[0m        \u001b[32m0.5999\u001b[0m       \u001b[35m0.6950\u001b[0m        \u001b[31m0.6277\u001b[0m  0.0806\n",
      "      8  \u001b[36m0.7443\u001b[0m        \u001b[32m0.5935\u001b[0m       \u001b[35m0.7100\u001b[0m        \u001b[31m0.6238\u001b[0m  0.0734\n",
      "      9  \u001b[36m0.7527\u001b[0m        \u001b[32m0.5866\u001b[0m       0.7000        \u001b[31m0.6095\u001b[0m  0.0858\n",
      "     10  \u001b[36m0.7607\u001b[0m        0.5904       0.7100        \u001b[31m0.6039\u001b[0m  0.0971\n",
      "     11  0.7595        \u001b[32m0.5699\u001b[0m       \u001b[35m0.7250\u001b[0m        \u001b[31m0.6007\u001b[0m  0.1063\n",
      "     12  0.7579        \u001b[32m0.5636\u001b[0m       0.7100        \u001b[31m0.5992\u001b[0m  0.1536\n",
      "     13  \u001b[36m0.7656\u001b[0m        \u001b[32m0.5634\u001b[0m       0.7200        \u001b[31m0.5903\u001b[0m  0.0948\n",
      "     14  \u001b[36m0.7715\u001b[0m        0.5687       \u001b[35m0.7350\u001b[0m        \u001b[31m0.5858\u001b[0m  0.0547\n",
      "     15  \u001b[36m0.7760\u001b[0m        \u001b[32m0.5372\u001b[0m       0.7250        0.5866  0.0547\n",
      "     16  \u001b[36m0.7788\u001b[0m        0.5490       \u001b[35m0.7400\u001b[0m        \u001b[31m0.5843\u001b[0m  0.0672\n",
      "     17  \u001b[36m0.7856\u001b[0m        0.5461       0.7250        \u001b[31m0.5689\u001b[0m  0.0734\n",
      "     18  \u001b[36m0.7881\u001b[0m        \u001b[32m0.5354\u001b[0m       0.7400        \u001b[31m0.5676\u001b[0m  0.0745\n",
      "     19  0.7863        0.5433       0.7350        \u001b[31m0.5674\u001b[0m  0.0823\n",
      "     20  0.7857        \u001b[32m0.5150\u001b[0m       \u001b[35m0.7450\u001b[0m        \u001b[31m0.5671\u001b[0m  0.0988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<skorch.net.NeuralNetClassifier at 0x7fb8c81b7630>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing your own callbacks is also straightforward. Just remember these rules:\n",
    "* They should inherit from `skorch.callbacks.Callback`.\n",
    "* They should implement at least one of the `on_`-methods provided by the parent class (e.g. `on_batch_begin` or `on_epoch_end`).\n",
    "* As argument, the `on_`-methods first get the `NeuralNet` instance, and, where appropriate, the local data (e.g. the data from the current batch). The method should also have `**kwargs` in the signature for potentially unused arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a callback that saves the model if the validation loss has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "\n",
    "\n",
    "class Checkpoint(Callback):\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        # check if valid accuracy of most recent epoch is the best so far\n",
    "        if net.history[-1, 'valid_acc_best']:\n",
    "            print(\"Save model to {}.\".format(self.file_name))\n",
    "            net.save_params(self.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    callbacks=[auc, Checkpoint(file_name)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to /tmp/mymodel.pkl.\n",
      "  epoch     AUC    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.5598\u001b[0m        \u001b[32m0.6962\u001b[0m       \u001b[35m0.5500\u001b[0m        \u001b[31m0.6894\u001b[0m  0.0941\n",
      "Save model to /tmp/mymodel.pkl.\n",
      "      2  \u001b[36m0.5648\u001b[0m        \u001b[32m0.6905\u001b[0m       \u001b[35m0.5550\u001b[0m        \u001b[31m0.6889\u001b[0m  0.0619\n",
      "Save model to /tmp/mymodel.pkl.\n",
      "      3  \u001b[36m0.5716\u001b[0m        0.6910       \u001b[35m0.5600\u001b[0m        \u001b[31m0.6883\u001b[0m  0.1134\n",
      "Save model to /tmp/mymodel.pkl.\n",
      "      4  \u001b[36m0.5773\u001b[0m        \u001b[32m0.6904\u001b[0m       \u001b[35m0.5650\u001b[0m        \u001b[31m0.6878\u001b[0m  0.0817\n",
      "      5  \u001b[36m0.5810\u001b[0m        0.6920       0.5650        \u001b[31m0.6873\u001b[0m  0.0709\n",
      "Save model to /tmp/mymodel.pkl.\n",
      "      6  \u001b[36m0.5880\u001b[0m        \u001b[32m0.6889\u001b[0m       \u001b[35m0.5700\u001b[0m        \u001b[31m0.6867\u001b[0m  0.1115\n",
      "      7  \u001b[36m0.5904\u001b[0m        0.6923       0.5600        \u001b[31m0.6862\u001b[0m  0.0659\n",
      "Save model to /tmp/mymodel.pkl.\n",
      "      8  \u001b[36m0.5912\u001b[0m        \u001b[32m0.6838\u001b[0m       \u001b[35m0.5750\u001b[0m        \u001b[31m0.6858\u001b[0m  0.0948\n",
      "Save model to /tmp/mymodel.pkl.\n",
      "      9  \u001b[36m0.5957\u001b[0m        0.6881       \u001b[35m0.5800\u001b[0m        \u001b[31m0.6853\u001b[0m  0.0810\n",
      "     10  \u001b[36m0.6012\u001b[0m        0.6891       0.5800        \u001b[31m0.6849\u001b[0m  0.0949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<skorch.net.NeuralNetClassifier at 0x7fb938c157f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Usage with sklearn `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. So e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optim__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module, iterator_train, iterator_test, optim, criterion, callbacks\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(net.prefixes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show how to perform a grid search over the learning rate (`lr`), the module's number of hidden units (`module__num_units`), the module's dropout rate (`module__dropout`), and whether the SGD optimizer should use Nesterov momentum or not (`optim__nesterov`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    verbose=0,\n",
    "    optim__momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0, 0.5],\n",
    "    'optim__nesterov': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=False, total=   1.1s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=False, total=   1.0s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=True, total=   1.0s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=True, total=   0.8s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optim__nesterov=True, total=   0.8s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=False, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=False, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=False, total=   0.8s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=True, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optim__nesterov=True, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=True, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optim__nesterov=True, total=   0.8s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=False, total=   0.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=False, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=True, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=True, total=   1.0s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optim__nesterov=True, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   45.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=<skorch.net.NeuralNetClassifier object at 0x7fb8c8176860>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'lr': [0.05, 0.1], 'module__num_units': [10, 20], 'module__dropout': [0, 0.5], 'optim__nesterov': [False, True]},\n",
       "       pre_dispatch='2*n_jobs', refit=False, return_train_score=True,\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856 {'lr': 0.1, 'module__dropout': 0, 'module__num_units': 20, 'optim__nesterov': True}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Of course, we could further nest the `NeuralNetClassifier` within an `sklearn Pipeline`, in which case we just prefix the parameter by the name of the net (e.g. `net__module__num_units`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
